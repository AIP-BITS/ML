{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e95b0be4",
   "metadata": {},
   "source": [
    "# Classification data-set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b900add",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "# define dataset\n",
    "X, y = make_classification(n_samples=10000, n_features=10, n_informative=5, n_redundant=5, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee3ff23",
   "metadata": {},
   "source": [
    "# Pipeline - to avoid data leak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a44d08de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 77.743 (1.296)\n"
     ]
    }
   ],
   "source": [
    "from numpy import mean\n",
    "from numpy import std\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# define the pipeline\n",
    "steps = list()\n",
    "steps.append(('scaler', MinMaxScaler()))\n",
    "steps.append(('model', LogisticRegression()))\n",
    "pipeline = Pipeline(steps=steps)\n",
    "\n",
    "# define the evaluation procedure\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# evaluate the model using cross-validation\n",
    "scores = cross_val_score(pipeline, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores)*100, std(scores)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0195ef01",
   "metadata": {},
   "source": [
    "# Basic Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65782ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Messy Datasets\n",
    "# 2. Identify Columns That Contain a Single Value\n",
    "# 3. Delete Columns That Contain a Single Value\n",
    "# 4. Consider Columns That Have Very Few Values\n",
    "# 5. Remove Columns That Have A Low Variance\n",
    "# 6. Identify Rows that Contain Duplicate Data\n",
    "# 7. Delete Rows that Contain Duplicate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58455379",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2558</th>\n",
       "      <th>1506.09</th>\n",
       "      <th>456.63</th>\n",
       "      <th>90</th>\n",
       "      <th>6395000</th>\n",
       "      <th>40.88</th>\n",
       "      <th>7.89</th>\n",
       "      <th>29780</th>\n",
       "      <th>0.19</th>\n",
       "      <th>214.7</th>\n",
       "      <th>0.21</th>\n",
       "      <th>0.26</th>\n",
       "      <th>0.49</th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.4</th>\n",
       "      <th>99.59</th>\n",
       "      <th>32.19</th>\n",
       "      <th>1.84</th>\n",
       "      <th>0.16</th>\n",
       "      <th>0.2</th>\n",
       "      <th>87.65</th>\n",
       "      <th>0</th>\n",
       "      <th>0.47</th>\n",
       "      <th>132.78</th>\n",
       "      <th>-0.01</th>\n",
       "      <th>3.78</th>\n",
       "      <th>0.22</th>\n",
       "      <th>3.2</th>\n",
       "      <th>-3.71</th>\n",
       "      <th>-0.18</th>\n",
       "      <th>2.19</th>\n",
       "      <th>0.1.1</th>\n",
       "      <th>2.19.1</th>\n",
       "      <th>310</th>\n",
       "      <th>16110</th>\n",
       "      <th>0.2.1</th>\n",
       "      <th>138.68</th>\n",
       "      <th>89</th>\n",
       "      <th>69</th>\n",
       "      <th>2850</th>\n",
       "      <th>1000</th>\n",
       "      <th>763.16</th>\n",
       "      <th>135.46</th>\n",
       "      <th>3.73</th>\n",
       "      <th>0.3</th>\n",
       "      <th>33243.19</th>\n",
       "      <th>65.74</th>\n",
       "      <th>7.95</th>\n",
       "      <th>1.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>22325</td>\n",
       "      <td>79.11</td>\n",
       "      <td>841.03</td>\n",
       "      <td>180</td>\n",
       "      <td>55812500.0</td>\n",
       "      <td>51.11</td>\n",
       "      <td>1.21</td>\n",
       "      <td>61900.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>901.7</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.11</td>\n",
       "      <td>6058.23</td>\n",
       "      <td>4061.15</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>87.65</td>\n",
       "      <td>0</td>\n",
       "      <td>0.58</td>\n",
       "      <td>132.78</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>3.78</td>\n",
       "      <td>0.84</td>\n",
       "      <td>7.09</td>\n",
       "      <td>-2.21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>704</td>\n",
       "      <td>40140</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68.65</td>\n",
       "      <td>89</td>\n",
       "      <td>69</td>\n",
       "      <td>5750.0</td>\n",
       "      <td>11500.0</td>\n",
       "      <td>9593.48</td>\n",
       "      <td>1648.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0</td>\n",
       "      <td>51572.04</td>\n",
       "      <td>65.73</td>\n",
       "      <td>6.26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   1   2558  1506.09  456.63   90  ...  0.3  33243.19  65.74  7.95  1.1\n",
       "0  2  22325    79.11  841.03  180  ...    0  51572.04  65.73  6.26    0\n",
       "\n",
       "[1 rows x 50 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "data = pd.read_csv(\"https://raw.githubusercontent.com/AIP-codedb/public/main/data/oil-spill.csv\")\n",
    "data.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a629326",
   "metadata": {},
   "source": [
    "# Select Categorical Input Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "41a802ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chi-Squared Statistic. \n",
    "# Mutual Information Statistic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478249f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.feature_selection import chi2\n",
    "from matplotlib import pyplot\n",
    "\n",
    "import pandas as pd\n",
    "data = pd.read_csv(\"https://raw.githubusercontent.com/AIP-codedb/public/main/data/breast-cancer.csv\",header=None)\n",
    "dataset = data.values\n",
    "X = dataset[:, :-1]\n",
    "y = dataset[:,-1]\n",
    "\n",
    "# format all fields as string\n",
    "X = X.astype(str)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "\n",
    "# prepare input data\n",
    "oe = OrdinalEncoder()\n",
    "oe.fit(X_train)\n",
    "X_train_enc = oe.transform(X_train)\n",
    "X_test_enc = oe.transform(X_test)\n",
    "\n",
    "# prepare output data\n",
    "le = LabelEncoder()\n",
    "le.fit(y_train)\n",
    "y_train_enc = le.transform(y_train)\n",
    "y_test_enc = le.transform(y_test)\n",
    "\n",
    "# feature selection\n",
    "fschi2 = SelectKBest(score_func=chi2, k=6) # 4 Features looks important\n",
    "fsmic = SelectKBest(score_func=mutual_info_classif, k=6) # few Features has zero importance\n",
    "\n",
    "fschi2.fit(X_train_enc, y_train_enc)\n",
    "X_train_fschi2 = fschi2.transform(X_train_enc)\n",
    "X_test_fschi2 = fschi2.transform(X_test_enc)\n",
    "\n",
    "fsmic.fit(X_train_enc, y_train_enc)\n",
    "X_train_fsmic = fsmic.transform(X_train_enc)\n",
    "X_test_fsmic = fsmic.transform(X_test_enc)\n",
    "\n",
    "# what are scores for the features\n",
    "for i in range(len(fschi2.scores_)):\n",
    "    print('Feature %d: %f' % (i, fschi2.scores_[i]))\n",
    "\n",
    "# plot the scores\n",
    "pyplot.bar([i for i in range(len(fschi2.scores_))], fschi2.scores_)\n",
    "pyplot.show()\n",
    "\n",
    "print(\"=============\")\n",
    "\n",
    "# what are scores for the features\n",
    "for i in range(len(fsmic.scores_)):\n",
    "    print('Feature %d: %f' % (i, fsmic.scores_[i]))\n",
    "\n",
    "# plot the scores\n",
    "pyplot.bar([i for i in range(len(fsmic.scores_))], fsmic.scores_)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6209435f",
   "metadata": {},
   "source": [
    "## Evaluation of a model using all input features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "041ae034",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((191, 9), (191, 6), (191, 6))"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_enc.shape, X_train_fschi2.shape, X_train_fsmic.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "b91c2d9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75.78947368421053\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# fit the model\n",
    "model = LogisticRegression(solver='lbfgs')\n",
    "model.fit(X_train_enc, y_train_enc)\n",
    "\n",
    "# evaluate the model\n",
    "yhat = model.predict(X_test_enc)\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test_enc, yhat)\n",
    "print(accuracy*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41cb7cfa",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Evaluation of a model using selected input features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "67fddd3f",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74.73684210526315\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# fit the model\n",
    "model = LogisticRegression(solver='lbfgs')\n",
    "model.fit(X_train_fschi2, y_train_enc)\n",
    "\n",
    "# evaluate the model\n",
    "yhat = model.predict(X_test_fschi2)\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test_enc, yhat)\n",
    "print(accuracy*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "aff3d840",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74.73684210526315\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# fit the model\n",
    "model = LogisticRegression(solver='lbfgs')\n",
    "model.fit(X_train_fsmic, y_train_enc)\n",
    "\n",
    "# evaluate the model\n",
    "yhat = model.predict(X_test_fsmic)\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test_enc, yhat)\n",
    "print(accuracy*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d0935e",
   "metadata": {},
   "source": [
    "# Select Numerical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d004bc46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANOVA F-Statistic. \n",
    "# Mutual Information Statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "42518339",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f \n",
    "\n",
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import f_classif\n",
    "\n",
    "from matplotlib import pyplot\n",
    "\n",
    "data = pd.read_csv(\"https://raw.githubusercontent.com/AIP-codedb/public/main/data/pima-indians-diabetes.csv\",header=None)\n",
    "dataset = data.values\n",
    "X = dataset[:, :-1]\n",
    "y = dataset[:,-1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "851f12f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature 0: 16.527385\n",
      "Feature 1: 131.325562\n",
      "Feature 2: 0.042371\n",
      "Feature 3: 1.415216\n",
      "Feature 4: 12.778966\n",
      "Feature 5: 49.209523\n",
      "Feature 6: 13.377142\n",
      "Feature 7: 25.126440\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# feature selection\n",
    "fsAF = SelectKBest(score_func=f_classif, k=4) \n",
    "\n",
    "fsAF.fit(X_train, y_train)\n",
    "X_train_fsAF = fsAF.transform(X_train)\n",
    "X_test_fsAF = fsAF.transform(X_test)\n",
    "\n",
    "# what are scores for the features\n",
    "for i in range(len(fsAF.scores_)):\n",
    "    print('Feature %d: %f' % (i, fsAF.scores_[i]))\n",
    "\n",
    "# plot the scores\n",
    "pyplot.bar([i for i in range(len(fsAF.scores_))], fsAF.scores_)\n",
    "pyplot.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "7a5f09cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((514, 8), (514, 4))"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_train_fsAF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "64ea26a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77.55905511811024\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# fit the model\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# evaluate the model\n",
    "yhat = model.predict(X_test)\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, yhat)\n",
    "print(accuracy*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "8ab9251a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78.74015748031496\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# fit the model\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "model.fit(X_train_fsAF, y_train)\n",
    "\n",
    "# evaluate the model\n",
    "yhat = model.predict(X_test_fsAF)\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, yhat)\n",
    "print(accuracy*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d52d6d6",
   "metadata": {},
   "source": [
    "# Numerical Feature selection for Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5f6f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation Statistics. \n",
    "# Mutual Information Statistics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af15329",
   "metadata": {},
   "source": [
    "## Model using all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "baa58709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08569191074140448\n"
     ]
    }
   ],
   "source": [
    "# evaluation of a model using all input features\n",
    "from sklearn.datasets import make_regression \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.linear_model import LinearRegression \n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# load the dataset \n",
    "X, y = make_regression(n_samples=1000, n_features=100, n_informative=10, noise=0.1, random_state=1)\n",
    "\n",
    "# split into train and test sets \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1) \n",
    "# fit the model \n",
    "model = LinearRegression() \n",
    "model.fit(X_train, y_train) \n",
    "# evaluate the model \n",
    "\n",
    "yhat = model.predict(X_test) \n",
    "# evaluate predictions \n",
    "mae = mean_absolute_error(y_test, yhat) \n",
    "print(mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9f5787",
   "metadata": {},
   "source": [
    "## Model using correlation features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "eb7e6c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 100)\n",
      "0.08245530329051184\n"
     ]
    }
   ],
   "source": [
    "# evaluation of a model using all input features\n",
    "from sklearn.datasets import make_regression \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.linear_model import LinearRegression \n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.feature_selection import f_regression\n",
    "\n",
    "# load the dataset \n",
    "X, y = make_regression(n_samples=1000, n_features=100, n_informative=10, noise=0.1, random_state=1)\n",
    "print(X.shape)\n",
    "# split into train and test sets \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1) \n",
    "\n",
    "# feature selection\n",
    "fs_corr = SelectKBest(score_func=f_regression, k=70)\n",
    "fs_corr.fit(X_train, y_train)\n",
    "X_train_fs_corr = fs_corr.transform(X_train)\n",
    "X_test_fs_corr = fs_corr.transform(X_test)\n",
    "\n",
    "# fit the model \n",
    "model = LinearRegression() \n",
    "model.fit(X_train_fs_corr, y_train) \n",
    "# evaluate the model \n",
    "\n",
    "yhat = model.predict(X_test_fs_corr) \n",
    "# evaluate predictions \n",
    "mae = mean_absolute_error(y_test, yhat) \n",
    "print(mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aac6db2",
   "metadata": {},
   "source": [
    "## Model using Mutual Information Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "5a87bf8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08256189653226677\n"
     ]
    }
   ],
   "source": [
    "# evaluation of a model using all input features\n",
    "from sklearn.datasets import make_regression \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.linear_model import LinearRegression \n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "\n",
    "# load the dataset \n",
    "X, y = make_regression(n_samples=1000, n_features=100, n_informative=10, noise=0.1, random_state=1)\n",
    "# split into train and test sets \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1) \n",
    "\n",
    "# feature selection\n",
    "fs_corr = SelectKBest(score_func=mutual_info_regression, k=70)\n",
    "fs_corr.fit(X_train, y_train)\n",
    "X_train_fs_corr = fs_corr.transform(X_train)\n",
    "X_test_fs_corr = fs_corr.transform(X_test)\n",
    "# fit the model \n",
    "model = LinearRegression() \n",
    "model.fit(X_train_fs_corr, y_train) \n",
    "# evaluate the model \n",
    "\n",
    "yhat = model.predict(X_test_fs_corr) \n",
    "# evaluate predictions \n",
    "mae = mean_absolute_error(y_test, yhat) \n",
    "print(mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2b7687",
   "metadata": {},
   "source": [
    "# RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "63215ddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score on training data:  0.7774666666666666\n",
      "accuracy_score on test data:  0.776\n",
      "Column: 0, Selected=True, Rank: 1\n",
      "Column: 1, Selected=True, Rank: 1\n",
      "Column: 2, Selected=False, Rank: 6\n",
      "Column: 3, Selected=False, Rank: 2\n",
      "Column: 4, Selected=True, Rank: 1\n",
      "Column: 5, Selected=False, Rank: 4\n",
      "Column: 6, Selected=False, Rank: 5\n",
      "Column: 7, Selected=True, Rank: 1\n",
      "Column: 8, Selected=True, Rank: 1\n",
      "Column: 9, Selected=False, Rank: 3\n",
      "accuracy_score on training data:  0.7774666666666666\n",
      "accuracy_score on test data:  0.7752\n"
     ]
    }
   ],
   "source": [
    "# report which features were selected by RFE\n",
    "from sklearn.datasets import make_classification\n",
    "# define dataset\n",
    "X, y = make_classification(n_samples=10000, n_features=10, n_informative=5, n_redundant=5, random_state=42)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "# scale the test dataset : only transform to avoid data leak\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "pred_train=clf.predict(X_train)\n",
    "print('accuracy_score on training data: ',accuracy_score(y_train,pred_train))\n",
    "\n",
    "pred_test=clf.predict(X_test)\n",
    "print('accuracy_score on test data: ',accuracy_score(y_test,pred_test))\n",
    "\n",
    "# define RFE\n",
    "from sklearn.feature_selection import RFE\n",
    "clf = RFE(estimator=LogisticRegression(), n_features_to_select=5)\n",
    "# fit RFE\n",
    "clf.fit(X_train,y_train)\n",
    "# summarize all features\n",
    "for i in range(X.shape[1]):\n",
    "\tprint('Column: %d, Selected=%s, Rank: %d' % (i, clf.support_[i], clf.ranking_[i]))\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "pred_train=clf.predict(X_train)\n",
    "print('accuracy_score on training data: ',accuracy_score(y_train,pred_train))\n",
    "\n",
    "pred_test=clf.predict(X_test)\n",
    "print('accuracy_score on test data: ',accuracy_score(y_test,pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5957cace",
   "metadata": {},
   "source": [
    "# Automatic RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "909289e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score on training data:  0.7774666666666666\n",
      "accuracy_score on test data:  0.776\n",
      "Column: 0, Selected=True, Rank: 1\n",
      "Column: 1, Selected=True, Rank: 1\n",
      "Column: 2, Selected=False, Rank: 4\n",
      "Column: 3, Selected=True, Rank: 1\n",
      "Column: 4, Selected=True, Rank: 1\n",
      "Column: 5, Selected=False, Rank: 2\n",
      "Column: 6, Selected=False, Rank: 3\n",
      "Column: 7, Selected=True, Rank: 1\n",
      "Column: 8, Selected=True, Rank: 1\n",
      "Column: 9, Selected=True, Rank: 1\n",
      "accuracy_score on training data:  0.7788\n",
      "accuracy_score on test data:  0.774\n"
     ]
    }
   ],
   "source": [
    "# report which features were selected by RFE\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.feature_selection import RFECV\n",
    "# define dataset\n",
    "X, y = make_classification(n_samples=10000, n_features=10, n_informative=5, n_redundant=5, random_state=42)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "# scale the test dataset : only transform to avoid data leak\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "pred_train=clf.predict(X_train)\n",
    "print('accuracy_score on training data: ',accuracy_score(y_train,pred_train))\n",
    "\n",
    "pred_test=clf.predict(X_test)\n",
    "print('accuracy_score on test data: ',accuracy_score(y_test,pred_test))\n",
    "\n",
    "# define RFE\n",
    "from sklearn.feature_selection import RFECV\n",
    "clf = RFECV(estimator=LogisticRegression())\n",
    "# fit RFE\n",
    "clf.fit(X_train,y_train)\n",
    "# summarize all features\n",
    "for i in range(X.shape[1]):\n",
    "\tprint('Column: %d, Selected=%s, Rank: %d' % (i, clf.support_[i], clf.ranking_[i]))\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "pred_train=clf.predict(X_train)\n",
    "print('accuracy_score on training data: ',accuracy_score(y_train,pred_train))\n",
    "\n",
    "pred_test=clf.predict(X_test)\n",
    "print('accuracy_score on test data: ',accuracy_score(y_test,pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bab032b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
